{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5be5c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from scipy.spatial.transform import Rotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3818e109",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quat_to_R(q):\n",
    "    x,y,z,w = q\n",
    "    s = np.linalg.norm([w,x,y,z])\n",
    "    w,x,y,z = w/s, x/s, y/s, z/s\n",
    "    R = np.array([\n",
    "        [1-2*(y*y+z*z),   2*(x*y - z*w),   2*(x*z + y*w)],\n",
    "        [2*(x*y + z*w),   1-2*(x*x+z*z),   2*(y*z - x*w)],\n",
    "        [2*(x*z - y*w),   2*(y*z + x*w),   1-2*(x*x+y*y)]\n",
    "    ])\n",
    "    return R\n",
    "\n",
    "\n",
    "\n",
    "# SHOUTOUT https://github.com/RealManRobot/hand_eye_calibration/blob/main/compute_to_hand.py\n",
    "def convert(x ,y ,z, rotation_matrix, translation_vector):\n",
    "    obj_camera_coordinates = np.array([x, y, z])\n",
    "    T_camera_to_base_effector = np.eye(4)\n",
    "    T_camera_to_base_effector[:3, :3] = rotation_matrix\n",
    "    T_camera_to_base_effector[:3, 3] = translation_vector.reshape(3)\n",
    "\n",
    "    # Compute the pose of the object against the base\n",
    "    obj_camera_coordinates_homo = np.append(obj_camera_coordinates, [1])  # Convert object coordinates to homogeneous coordinates\n",
    "    obj_base_effector_coordinates_homo = T_camera_to_base_effector.dot(obj_camera_coordinates_homo)\n",
    "    obj_base_coordinates = obj_base_effector_coordinates_homo[:3]  \n",
    "\n",
    "    rot_matrix_homo = T_camera_to_base_effector[:3, :3]\n",
    "    quaternion = Rotation.from_matrix(rot_matrix_homo).as_quat()\n",
    "\n",
    "    return list(obj_base_coordinates), quaternion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9157091d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 4 snapshots (ABB robtarget-like) ---\n",
    "# base -> gripper\n",
    "abb_pos_mm = [  # x, y, z in mm\n",
    "    [100,   0, 200],   # pose 0\n",
    "    [120,  20, 220],   # pose 1\n",
    "    [ 80, -30, 250],   # pose 2\n",
    "    [150,  10, 180],   # pose 3\n",
    "]\n",
    "\n",
    "# quaternions (x, y, z, w)\n",
    "# pose0: identity\n",
    "# pose1: +10° about Z\n",
    "# pose2: +10° about X\n",
    "# pose3: +10° about Y\n",
    "s = 0.0871557   # sin(10°/2)\n",
    "c = 0.9961947   # cos(10°/2)\n",
    "abb_quat_xyzw = [\n",
    "    [0.0, 0.0, 0.0, 1.0],    # pose 0\n",
    "    [0.0, 0.0, s,   c],      # pose 1  (Z)\n",
    "    [s,   0.0, 0.0, c],      # pose 2  (X)\n",
    "    [0.0, s,   0.0, c],      # pose 3  (Y)\n",
    "]\n",
    "\n",
    "\n",
    "# rvec_t2c: target(board) -> camera  (Rodrigues, radians)\n",
    "rvec_t2c = [\n",
    "    [0.0,     0.0,     0.26180],  # ~15° yaw\n",
    "    [0.0,     0.0,     0.52360],  # ~30° yaw\n",
    "    [0.17453, 0.0,     0.26180],  # ~10° pitch + 15° yaw\n",
    "    [0.0,     0.17453, 0.34907],  # ~10° roll  + 20° yaw\n",
    "]\n",
    "\n",
    "# t_t2c: target(board) -> camera (meters)\n",
    "t_t2c = [\n",
    "    [-100,  20,  500.0],\n",
    "    [-120.0,  10.0,  500.0],\n",
    "    [-90.0, -20.0,  520.0],\n",
    "    [-110.0,  30.0,  480.0],\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "46f3049b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' R_b2g = quat_to_R(abb_quat_xyzw)\\nt_b2g = [np.array(tv, np.float64).reshape(3,1) for tv in abb_pos_mm]\\n#print(R_b2g)\\n#print(t_b2g)\\n\\n#R_g2b = R_b2g.T\\n#t_g2b = - R_b2g.T @ t_b2g\\n#print(R_g2b, t_g2b)\\n\\n\\nR_g2b, t_g2b = [], []\\nfor pos, quat in zip(abb_pos_mm, abb_quat_xyzw):\\n    R_b2g = quat_to_R(quat)                                 # (3,3)\\n    t_b2g = np.asarray(pos, np.float64).reshape(3,1)  #  (3,1)\\n    # invert to gripper->base\\n    R_gb = R_b2g.T\\n    t_gb = - R_gb @ t_b2g\\n    R_g2b.append(R_gb)\\n    t_g2b.append(t_gb) '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" R_b2g = quat_to_R(abb_quat_xyzw)\n",
    "t_b2g = [np.array(tv, np.float64).reshape(3,1) for tv in abb_pos_mm]\n",
    "#print(R_b2g)\n",
    "#print(t_b2g)\n",
    "\n",
    "#R_g2b = R_b2g.T\n",
    "#t_g2b = - R_b2g.T @ t_b2g\n",
    "#print(R_g2b, t_g2b)\n",
    "\n",
    "\n",
    "R_g2b, t_g2b = [], []\n",
    "for pos, quat in zip(abb_pos_mm, abb_quat_xyzw):\n",
    "    R_b2g = quat_to_R(quat)                                 # (3,3)\n",
    "    t_b2g = np.asarray(pos, np.float64).reshape(3,1)  #  (3,1)\n",
    "    # invert to gripper->base\n",
    "    R_gb = R_b2g.T\n",
    "    t_gb = - R_gb @ t_b2g\n",
    "    R_g2b.append(R_gb)\n",
    "    t_g2b.append(t_gb) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fcae6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.89841564 -0.06666992 -0.43405582]\n",
      " [ 0.25785393  0.88016718  0.39851862]\n",
      " [ 0.35547249 -0.46995836  0.80794706]] [[ 374.39972847]\n",
      " [ -44.7444923 ]\n",
      " [-505.59544599]]\n"
     ]
    }
   ],
   "source": [
    "#R_b2g = quat_to_R(abb_quat_xyzw)\n",
    "#t_b2g = [np.array(tv, np.float64).reshape(3,1) for tv in abb_pos_mm]\n",
    "#print(R_b2g)\n",
    "#print(t_b2g)\n",
    "\n",
    "#R_g2b = R_b2g.T\n",
    "#t_g2b = - R_b2g.T @ t_b2g\n",
    "#print(R_g2b, t_g2b)\n",
    "\n",
    "\n",
    "\n",
    "def camera2robot_calib(position_robot, quat_robot, rotation_vec_t2c, translation_t2c):\n",
    "    R_g2b, t_g2b = [], []\n",
    "    for pos, quat in zip(position_robot, quat_robot): #position robot list of XYZ for each position of calibration and quat is its quaternion\n",
    "        R_b2g = quat_to_R(quat)                                 # (3,3)\n",
    "        t_b2g = np.asarray(pos, np.float64).reshape(3,1)  #  (3,1)\n",
    "        # invert to gripper->base\n",
    "        R_gb = R_b2g.T\n",
    "        t_gb = - R_gb @ t_b2g\n",
    "        R_g2b.append(R_gb)\n",
    "        t_g2b.append(t_gb)\n",
    "\n",
    "    R_t2c = [cv.Rodrigues(np.array(rv, np.float64))[0] for rv in rotation_vec_t2c]\n",
    "    t_t2c = [np.array(tv, np.float64).reshape(3,1)     for tv in translation_t2c]\n",
    "\n",
    "    R_cam2gripper, t_cam2gripper = cv.calibrateHandEye(\n",
    "        R_gripper2base=R_g2b, t_gripper2base=t_g2b,\n",
    "        R_target2cam=R_t2c,   t_target2cam=t_t2c,\n",
    "        method=cv.CALIB_HAND_EYE_DANIILIDIS\n",
    "    )\n",
    "    return R_cam2gripper, t_cam2gripper\n",
    "\n",
    "# 旋转矩阵\n",
    "#rotation = Rotation.from_matrix(R_cam2gripper)\n",
    "# 将旋转矩阵转换为四元数\n",
    "#print(\"Rotation matrix, R_cam2gripper:\\n\", R_cam2gripper)\n",
    "#print(\"Traslation vector, t_cam2gripper:\\n\", t_cam2gripper)\n",
    "#print(\"Quaternion based on rotation matrix from cam2gripper: \\n\",quaternion)\n",
    "\n",
    "R_cam2gripper, t_cam2gripper = camera2robot_calib(abb_pos_mm, abb_quat_xyzw, rvec_t2c, t_t2c)\n",
    "print(R_cam2gripper, t_cam2gripper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "393b0773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([510.8334285533251, -35.36078412661436, -294.59120076445066],\n",
       " array([-0.22929315, -0.20844932,  0.08567999,  0.94690679]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert(200, -100 , 115 , R_cam2gripper, t_cam2gripper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "580a5d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' #\\nimport numpy as np\\nimport cv2 as cv\\nfrom scipy.spatial.transform import Rotation\\n\\ndef quat_to_R(q):\\n    x,y,z,w = q\\n    # normalize\\n    s = np.linalg.norm([w,x,y,z])\\n    w,x,y,z = w/s, x/s, y/s, z/s\\n    R = np.array([\\n        [1-2*(y*y+z*z),   2*(x*y - z*w),   2*(x*z + y*w)],\\n        [2*(x*y + z*w),   1-2*(x*x+z*z),   2*(y*z - x*w)],\\n        [2*(x*z - y*w),   2*(y*z + x*w),   1-2*(x*x+y*y)]\\n    ])\\n    return R\\n\\n\\nR_b2g = quat_to_R(abb_quat_xyzw)\\nt_b2g = [np.array(tv, np.float64).reshape(3,1) for tv in abb_pos_mm]\\n#print(R_b2g)\\n#print(t_b2g)\\n\\nR_g2b = R_b2g.T\\nt_g2b = - R_b2g.T @ t_b2g\\n#print(R_g2b, t_g2b)\\n\\n\\n\\nR_t2c = [cv.Rodrigues(np.array(rv, np.float64))[0] for rv in rvec_t2c]\\nt_t2c = [np.array(tv, np.float64).reshape(3,1)     for tv in t_t2c]\\n\\nR_cam2gripper, t_cam2gripper = cv.calibrateHandEye(\\n    R_gripper2base=R_g2b, t_gripper2base=t_g2b,\\n    R_target2cam=R_t2c,   t_target2cam=t_t2c,\\n    method=cv.CALIB_HAND_EYE_DANIILIDIS\\n)\\n\\nrotation = Rotation.from_matrix(R_cam2gripper)\\nquaternion = rotation.as_quat() # \\n\\nprint(\"Rotation matrix, R_cam2gripper:\\n\", R_cam2gripper)\\nprint(\"Traslation vector, t_cam2gripper:\\n\", t_cam2gripper)\\n\\n\\n\\n '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" #\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from scipy.spatial.transform import Rotation\n",
    "\n",
    "def quat_to_R(q):\n",
    "    x,y,z,w = q\n",
    "    # normalize\n",
    "    s = np.linalg.norm([w,x,y,z])\n",
    "    w,x,y,z = w/s, x/s, y/s, z/s\n",
    "    R = np.array([\n",
    "        [1-2*(y*y+z*z),   2*(x*y - z*w),   2*(x*z + y*w)],\n",
    "        [2*(x*y + z*w),   1-2*(x*x+z*z),   2*(y*z - x*w)],\n",
    "        [2*(x*z - y*w),   2*(y*z + x*w),   1-2*(x*x+y*y)]\n",
    "    ])\n",
    "    return R\n",
    "\n",
    "\n",
    "R_b2g = quat_to_R(abb_quat_xyzw)\n",
    "t_b2g = [np.array(tv, np.float64).reshape(3,1) for tv in abb_pos_mm]\n",
    "#print(R_b2g)\n",
    "#print(t_b2g)\n",
    "\n",
    "R_g2b = R_b2g.T\n",
    "t_g2b = - R_b2g.T @ t_b2g\n",
    "#print(R_g2b, t_g2b)\n",
    "\n",
    "\n",
    "\n",
    "R_t2c = [cv.Rodrigues(np.array(rv, np.float64))[0] for rv in rvec_t2c]\n",
    "t_t2c = [np.array(tv, np.float64).reshape(3,1)     for tv in t_t2c]\n",
    "\n",
    "R_cam2gripper, t_cam2gripper = cv.calibrateHandEye(\n",
    "    R_gripper2base=R_g2b, t_gripper2base=t_g2b,\n",
    "    R_target2cam=R_t2c,   t_target2cam=t_t2c,\n",
    "    method=cv.CALIB_HAND_EYE_DANIILIDIS\n",
    ")\n",
    "\n",
    "rotation = Rotation.from_matrix(R_cam2gripper)\n",
    "quaternion = rotation.as_quat() # \n",
    "\n",
    "print(\"Rotation matrix, R_cam2gripper:\\n\", R_cam2gripper)\n",
    "print(\"Traslation vector, t_cam2gripper:\\n\", t_cam2gripper)\n",
    "\n",
    "\n",
    "\n",
    " \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
